import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import os
import numpy as np

# å¯¼å…¥ä½ å®šä¹‰çš„æ¨¡å—
from PhysicsGuidedNetwork import PhysicsGuidedNet
from PhysicsGuidedDataset import PhysicsGuidedHDF5Dataset

# ================= 1. è·¯å¾„ä¸ç¡¬ä»¶é…ç½® =================
H5_PATH = "/root/autodl-tmp/merged_dataset_512_3d_fast_v2.h5"  # ç¡®ä¿è·¯å¾„ä¸ç”Ÿæˆè„šæœ¬ä¸€è‡´
SAVE_PATH = "best_model_symmetric.pth"
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ================= 2. è¶…å‚æ•°é…ç½® =================
BATCH_SIZE = 64  # ä¼˜åŒ– H5 åå¯å°è¯•å¢å¤§è‡³ 64 æˆ– 128
NUM_WORKERS = 8  # AutoDL å»ºè®®è®¾ä¸º 8-16
LR = 1e-4
EPOCHS = 50
SCENE_SIZE = 5000.0


# ================= 3. ç‰©ç†ä¸€è‡´æ€§å¢å¼ºå‡½æ•° (ä¿æŒ) =================
def apply_augmentation(iq, heatmap, coord, mask):
    """
    åœ¨ GPU ä¸Šè¿›è¡Œæ•°æ®å¢å¼ºï¼Œä¿æŒ IQ é€šé“ä¸å‡ ä½•ç¿»è½¬çš„ä¸€è‡´æ€§
    """
    # éšæœºæ°´å¹³ç¿»è½¬
    if np.random.rand() > 0.5:
        heatmap = torch.flip(heatmap, [3])
        mask = torch.flip(mask, [3])
        coord[:, 0] = 1.0 - coord[:, 0]
        # H-Flip ç´¢å¼•äº¤æ¢: Rx0<->Rx1, Rx3<->Rx2
        idx_perm = torch.tensor([1, 0, 3, 2, 5, 4, 7, 6], device=iq.device)
        iq = iq[:, idx_perm, :]

    # éšæœºå‚ç›´ç¿»è½¬
    if np.random.rand() > 0.5:
        heatmap = torch.flip(heatmap, [2])
        mask = torch.flip(mask, [2])
        coord[:, 1] = 1.0 - coord[:, 1]
        # V-Flip ç´¢å¼•äº¤æ¢: Rx0<->Rx3, Rx1<->Rx2
        idx_perm = torch.tensor([3, 2, 1, 0, 7, 6, 5, 4], device=iq.device)
        iq = iq[:, idx_perm, :]

    return iq, heatmap, coord, mask


# ================= 4. Loss å®šä¹‰ =================
class DiceLoss(nn.Module):
    def __init__(self, smooth=1.0):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, pred_logits, target):
        pred_probs = torch.sigmoid(pred_logits)
        intersection = (pred_probs * target).sum()
        dice = (2. * intersection + self.smooth) / (pred_probs.sum() + target.sum() + self.smooth)
        return 1 - dice


# ================= 5. éªŒè¯å‡½æ•° (ä¼˜åŒ–ç‰ˆ) =================
def validate(model, loader, criterion_coord, criterion_bce, criterion_dice):
    model.eval()
    total_dist_err = 0.0
    num_samples = 0

    with torch.no_grad():
        for iq, heatmap, coord, mask in loader:
            iq, heatmap, coord, mask = iq.to(DEVICE), heatmap.to(DEVICE), coord.to(DEVICE), mask.to(DEVICE)

            # æ··åˆç²¾åº¦æ¨ç†
            with torch.cuda.amp.autocast():
                pred_coord, _ = model(iq, heatmap)

            dist_err = torch.norm(pred_coord - coord[:, :2], dim=1) * SCENE_SIZE
            total_dist_err += dist_err.sum().item()
            num_samples += iq.size(0)

    return total_dist_err / num_samples


# ================= 6. ä¸»è®­ç»ƒç¨‹åº =================
def main():
    print(f"ğŸš€ å¯åŠ¨æé€Ÿç‰ˆè®­ç»ƒ | è®¾å¤‡: {DEVICE} | Workers: {NUM_WORKERS}")

    # 1. åŠ è½½æ•°æ®é›†
    full_dataset = PhysicsGuidedHDF5Dataset(H5_PATH)
    train_size = int(0.9 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_ds, val_ds = random_split(full_dataset, [train_size, val_size])

    # 2. åˆ›å»º DataLoader (å¼€å¯é¢„å–åŠ é€Ÿ)
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,
                              num_workers=NUM_WORKERS, pin_memory=True, prefetch_factor=2)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,
                            num_workers=4, pin_memory=True)

    # 3. åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    model = PhysicsGuidedNet(num_rx=4, signal_len=2048).to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-3)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)

    # æ··åˆç²¾åº¦ç¼©æ”¾å™¨
    scaler = torch.cuda.amp.GradScaler()

    # 4. Loss å®šä¹‰
    criterion_coord = nn.L1Loss()
    criterion_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([20.0]).to(DEVICE))
    criterion_dice = DiceLoss()

    best_err = float('inf')

    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0.0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS}")

        for iq, heatmap, coord, mask in pbar:
            iq, heatmap, coord, mask = iq.to(DEVICE), heatmap.to(DEVICE), coord.to(DEVICE), mask.to(DEVICE)

            # åº”ç”¨æ•°æ®å¢å¼º
            iq, heatmap, coord, mask = apply_augmentation(iq, heatmap, coord, mask)

            optimizer.zero_grad()

            # --- å¼€å¯æ··åˆç²¾åº¦è®­ç»ƒ ---
            with torch.cuda.amp.autocast():
                pred_coord, pred_mask = model(iq, heatmap)

                loss_c = criterion_coord(pred_coord, coord[:, :2])
                loss_m = criterion_bce(pred_mask, mask) + criterion_dice(pred_mask, mask)

                # åŠ¨æ€è°ƒæ•´ Mask æƒé‡
                mask_w = 0.5 if epoch < 20 else 0.1
                total_loss = loss_c + mask_w * loss_m

            # åå‘ä¼ æ’­ç¼©æ”¾
            scaler.scale(total_loss).backward()
            scaler.step(optimizer)
            scaler.update()

            train_loss += total_loss.item()
            pbar.set_postfix({'loss': f"{total_loss.item():.4f}"})

        # éªŒè¯
        val_err = validate(model, val_loader, criterion_coord, criterion_bce, criterion_dice)
        print(f"Epoch {epoch + 1} éªŒè¯å®Œæˆ: å¹³å‡è¯¯å·® = {val_err:.2f}m")

        scheduler.step(val_err)

        if val_err < best_err:
            best_err = val_err
            torch.save(model.state_dict(), SAVE_PATH)
            print(f"ğŸŒŸ å‘ç°æ›´ä¼˜æ¨¡å‹: {best_err:.2f}m")


if __name__ == '__main__':
    main()